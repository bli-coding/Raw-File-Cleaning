{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "csv_file_path = \"<<Your Path>>\"\n",
    "\n",
    "with open(csv_file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "    raw_content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_counts_and_values_between_commas(raw_data):\n",
    "    # Split the raw data into lines\n",
    "    lines = raw_data.split('\\n')\n",
    "    \n",
    "    # Initialize empty lists to store the comma counts and values between the first and second comma\n",
    "    comma_counts = []\n",
    "    values_between_commas = []\n",
    "    \n",
    "    # Iterate through the lines\n",
    "    for line in lines:\n",
    "        # Find the position of the first \"http:\"\n",
    "        http_position = line.find(\"http:\")\n",
    "        \n",
    "        if http_position != -1:\n",
    "            # Count the commas before the first \"http:\"\n",
    "            comma_count = line[:http_position].count(',')\n",
    "            comma_counts.append(comma_count)\n",
    "            \n",
    "            # Find the position of the first comma after \"http:\"\n",
    "            first_comma_position = line.find(',')\n",
    "            \n",
    "            if first_comma_position != -1:\n",
    "                # Find the position of the second comma after the first comma\n",
    "                second_comma_position = line[first_comma_position + 1:].find(',')\n",
    "                \n",
    "                if second_comma_position != -1:\n",
    "                    # Extract the value between the first and second comma and append to the list\n",
    "                    value_between_commas = line[first_comma_position + 1:first_comma_position + second_comma_position + 1]\n",
    "                    values_between_commas.append(value_between_commas)\n",
    "                else:\n",
    "                    values_between_commas.append(-100)\n",
    "        else:\n",
    "            first_comma_position = line.find(',')\n",
    "            comma_counts.append(-100)\n",
    "            \n",
    "            if first_comma_position != -1:\n",
    "                # Find the position of the second comma after the first comma\n",
    "                second_comma_position = line[first_comma_position + 1:].find(',')\n",
    "                \n",
    "                if second_comma_position != -1:\n",
    "                    # Extract the value between the first and second comma and append to the list\n",
    "                    value_between_commas = line[first_comma_position + 1:first_comma_position + second_comma_position + 1]\n",
    "                    values_between_commas.append(value_between_commas)\n",
    "                else:\n",
    "                    values_between_commas.append(-100)\n",
    "\n",
    "    \n",
    "    return comma_counts, values_between_commas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comma_counts, values_between_commas = extract_counts_and_values_between_commas(raw_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        comma count  uniqueID\n",
      "0              -100  UniqueID\n",
      "1               134         9\n",
      "2               134        10\n",
      "3               134        11\n",
      "4               134        12\n",
      "...             ...       ...\n",
      "357585          134    403968\n",
      "357586          134    403969\n",
      "357587          134    403970\n",
      "357588          134    403971\n",
      "357589          134    403972\n",
      "\n",
      "[357590 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = {'comma count': comma_counts, 'uniqueID': values_between_commas}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('count_comma.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_comma_number(raw_data):\n",
    "    lines = raw_data.split('\\n')\n",
    "    column_row = lines[0]\n",
    "    column_value_to_find = \"Privacy Policy\"\n",
    "    index_of_keyword = column_row.find(column_value_to_find)\n",
    "    number_of_comma_before_keyword = column_row[:index_of_keyword].count(\",\")\n",
    "\n",
    "    return number_of_comma_before_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_counts_and_values_between_commas(raw_data, correct_comma_count):\n",
    "    # Split the raw data into lines\n",
    "    lines = raw_data.split('\\n')\n",
    "\n",
    "    # Initialize empty lists to store the comma counts and values between the first and second comma\n",
    "\n",
    "    Line_need_clean = []\n",
    "    Line_untouched = []\n",
    "\n",
    "\n",
    "    column_row = lines[0]\n",
    "    new_column_row = (\"num_count,\" + column_row)\n",
    "\n",
    "    Line_need_clean.append(new_column_row)\n",
    "    Line_untouched.append(new_column_row)\n",
    "    \n",
    "    # Iterate through the lines\n",
    "    for line in lines[1:]:\n",
    "        # Find the position of the first \"http:\"\n",
    "        http_position = line.find(\"http:\")\n",
    "        \n",
    "        if http_position != -1:\n",
    "            # Count the commas before the first \"http:\"\n",
    "            comma_count = line[:http_position].count(',')\n",
    "            if comma_count != correct_comma_count:\n",
    "                Line_need_clean.append(str(comma_count)+\",\"+line)\n",
    "            else:\n",
    "                Line_untouched.append(str(comma_count)+\",\"+line)\n",
    "        else:\n",
    "            Line_need_clean.append(\"-1000,\"+line)\n",
    "\n",
    "    Leave_alone_df = \"\\n\".join(Line_untouched)\n",
    "    Need_clean_df = \"\\n\".join(Line_need_clean)\n",
    "    \n",
    "    return Leave_alone_df,  Need_clean_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path_directory = \"<<Your Path>>\"\n",
    "\n",
    "csv_file_path_name_untouched = \"/untouched_Privacy Policy.csv\"\n",
    "\n",
    "csv_file_path_name_needs_clean = \"/needs_clean_Privacy Policy.csv\"\n",
    "\n",
    "csv_file_path_untouched = csv_file_path_directory + csv_file_path_name_untouched\n",
    "csv_file_path_needs_clean = csv_file_path_directory + csv_file_path_name_needs_clean\n",
    "\n",
    "with open(csv_file_path_untouched, \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "    raw_content_untouched = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
